<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>AgroSphere Agent (Voice)</title>
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      display: flex; justify-content: center; align-items: center; flex-direction: column;
      background-color: #f4f7f6; color: #333; height: 100vh; margin: 0;
    }
    #container {
      width: 90%; max-width: 600px; background: #fff; border-radius: 12px;
      box-shadow: 0 8px 30px rgba(0,0,0,0.1); padding: 2rem; text-align: center;
    }
    h1 { color: #0062ff; }
    #recordButton {
      width: 100px; height: 100px; border-radius: 50%; border: none; background-color: #0062ff;
      color: #fff; font-size: 1.2rem; font-weight: bold; cursor: pointer; transition: background-color .3s;
    }
    #recordButton.recording { background-color: #d72c2c; animation: pulse 1.5s infinite; }
    #status { font-size: 1.1rem; margin-top: 1.5rem; min-height: 2em; color: #555; }
    @keyframes pulse {
      0% { box-shadow: 0 0 0 0 rgba(215,44,44,.7); }
      70% { box-shadow: 0 0 0 20px rgba(215,44,44,0); }
      100% { box-shadow: 0 0 0 0 rgba(215,44,44,0); }
    }
  </style>
</head>
<body>
  <div id="container">
    <h1>AgroSphere Agent</h1>
    <button id="recordButton">Hold to Talk</button>
    <div id="status">Press and hold the button to ask a question.</div>
    <pre id="response" style="margin-top:1rem; text-align:left; background:#f8f9fb;
      padding:1rem; border-radius:8px; white-space:pre-wrap; word-wrap:break-word;"></pre>
  </div>

  <script>
    const recordButton = document.getElementById('recordButton');
    const statusDiv = document.getElementById('status');
    const responseEl = document.getElementById('response');

    let mediaRecorder;
    let audioChunks = [];
    let watsonAgentThreadId;

    async function transcribeAudio(audioBlob) {
      statusDiv.textContent = "Transcribing your voice...";
      const res = await fetch('/api/stt', {
        method: 'POST',
        headers: { 'Content-Type': audioBlob.type || 'audio/webm' },
        body: audioBlob
      });
      const data = await res.json();
      if (data.results && data.results[0] && data.results[0].alternatives[0]) {
        return data.results[0].alternatives[0].transcript;
      }
      throw new Error("Could not transcribe audio.");
    }

    async function askAgent(textQuery) {
      statusDiv.textContent = "Agent is thinking...";
      const res = await fetch('/api/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text: textQuery, thread_id: watsonAgentThreadId })
      });
      const data = await res.json();
      if (data.thread_id) watsonAgentThreadId = data.thread_id;

      if (data.output && data.output.generic) {
        const textResponse = data.output.generic.find(g => g.response_type === 'text');
        if (textResponse) return textResponse.text;
      }
      if (data.output?.text) return data.output.text;
      throw new Error("Agent did not return a text response.");
    }

    async function speakText(textResponse) {
      // show text on screen
      responseEl.textContent = textResponse || "(no text)";
      statusDiv.textContent = "Agent is replying...";

      // call TTS (in demo mode, server may return empty audio)
      const res = await fetch('/api/tts', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text: textResponse })
      });

      if (res.ok) {
        try {
          const blob = await res.blob();
          if (blob.size > 0) {
            const url = URL.createObjectURL(blob);
            const audio = new Audio(url);
            await new Promise((resolve) => { audio.onended = resolve; audio.play(); });
          }
        } catch { /* ignore audio errors */ }
      }
      statusDiv.textContent = "Press and hold the button to ask a question.";
    }

    async function startRecording() {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
      audioChunks = [];

      mediaRecorder.ondataavailable = (e) => audioChunks.push(e.data);
      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
        try {
          const userQuery = await transcribeAudio(audioBlob);
          const agentResponse = await askAgent(userQuery);
          await speakText(agentResponse);
        } catch (err) {
          console.error(err);
          statusDiv.textContent = `Error: ${err.message}`;
          try { await speakText(`I am sorry, I encountered an error. ${err.message}`); } catch {}
        }
      };

      mediaRecorder.start();
      recordButton.classList.add('recording');
      statusDiv.textContent = "Listening...";
    }

    function stopRecording() {
      if (mediaRecorder && mediaRecorder.state === "recording") {
        mediaRecorder.stop();
        recordButton.classList.remove('recording');
      }
    }

    recordButton.addEventListener('mousedown', startRecording);
    recordButton.addEventListener('mouseup', stopRecording);
    recordButton.addEventListener('touchstart', (e) => { e.preventDefault(); startRecording(); });
    recordButton.addEventListener('touchend', (e) => { e.preventDefault(); stopRecording(); });
  </script>
</body>
</html>
